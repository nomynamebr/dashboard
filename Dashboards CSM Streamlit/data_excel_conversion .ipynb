{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to merged_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import os\n",
    "\n",
    "# Initialize the WebDriver\n",
    "def initialize_driver():\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    site_url = \"https://prod-bop.securiti.xyz/\"\n",
    "    driver.get(site_url)\n",
    "    return driver\n",
    "\n",
    "# Wait for user interaction in the browser\n",
    "def wait_for_user():\n",
    "    print(\"Browser is open. Please log in to the site if required.\")\n",
    "    input(\"Press Enter in the terminal when you are ready to continue...\")\n",
    "    print(\"Continuing the script...\")\n",
    "\n",
    "# Retrieve cookies from the browser session\n",
    "def get_cookies(driver):\n",
    "    selenium_cookies = driver.get_cookies()\n",
    "    return {cookie['name']: cookie['value'] for cookie in selenium_cookies}\n",
    "\n",
    "# Fetch data from API and save as JSON\n",
    "def fetch_and_save_data(api_url, filename, cookies):\n",
    "    try:\n",
    "        response = requests.get(api_url, cookies=cookies)\n",
    "        response.raise_for_status()\n",
    "        data = response.json().get(\"data\", [])\n",
    "        \n",
    "        with open(filename, \"w\") as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "        \n",
    "        print(f\"Data successfully saved to {filename}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred while fetching {filename}: {e}\")\n",
    "\n",
    "# Convert epoch time to human-readable format\n",
    "def convert_epoch_to_human(epoch_time, timezone='UTC'):\n",
    "    epoch_time_seconds = epoch_time / 1000  # Convert milliseconds to seconds\n",
    "    tz = pytz.timezone(timezone)\n",
    "    dt = datetime.fromtimestamp(epoch_time_seconds, tz=pytz.utc).astimezone(tz)\n",
    "    return dt.strftime('%m-%d-%Y')\n",
    "\n",
    "# Process JSON files and save data to an Excel file\n",
    "def process_json_to_excel():\n",
    "    # Keywords to identify timestamp columns\n",
    "    keywords = ['created_at', 'modified_at', 'timestamp', 'last_scan_timestamp', 'next_scan_timestamp', 'published_at']\n",
    "    \n",
    "    # Specify the timezone\n",
    "    timezone = 'UTC'\n",
    "\n",
    "    # Create an Excel writer\n",
    "    excel_writer = pd.ExcelWriter('processed_data.xlsx', engine='openpyxl')\n",
    "\n",
    "    # Iterate over the 7 JSON files\n",
    "    for i in range(1, 8):\n",
    "        filename = f\"{i}-pod.json\"\n",
    "        if os.path.exists(filename):  # Ensure file exists\n",
    "            try:\n",
    "                # Read JSON file into DataFrame\n",
    "                data = pd.read_json(filename)\n",
    "                \n",
    "                # Process timestamp columns\n",
    "                for column in data.columns:\n",
    "                    if any(keyword in column.lower() for keyword in keywords):\n",
    "                        data[column] = data[column].apply(\n",
    "                            lambda x: convert_epoch_to_human(x, timezone) if isinstance(x, (int, float)) and x > 1_000_000_000_000 else x\n",
    "                        )\n",
    "                \n",
    "                # Write DataFrame to the Excel sheet\n",
    "                data.to_excel(excel_writer, sheet_name=f\"Sheet{i}\", index=False)\n",
    "                print(f\"Processed {filename} and saved to Excel.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "    \n",
    "    # Save the Excel file\n",
    "    excel_writer.save()\n",
    "    print(\"Data processed and saved to 'processed_data.xlsx'.\")\n",
    "\n",
    "# Main script\n",
    "def main():\n",
    "    driver = initialize_driver()\n",
    "    \n",
    "    # Wait for user to perform actions in the browser\n",
    "    wait_for_user()\n",
    "    \n",
    "    # Navigate to the tenant site\n",
    "    site_tenant = \"https://app.securiti.ai/#/\"\n",
    "    driver.get(site_tenant)\n",
    "    \n",
    "    # Get cookies from the browser session\n",
    "    cookies = get_cookies(driver)\n",
    "    \n",
    "    # Define API endpoints and corresponding filenames\n",
    "    endpoints = [\n",
    "        (\"https://app.securiti.ai/core/v1/admin/appliance\", \"1-pod.json\"),\n",
    "        (\"https://app.securiti.ai/privaci/v1/admin/datasources?sort=name&p=1&limit=35&ds_connector_type=cloud&ds_connector_type=onprem\", \"2-data_systems.json\"),\n",
    "        (\"https://app.securiti.ai/privaci/v1/admin/customer_storage\", \"3-private_cloud_storage.json\"),\n",
    "        (\"https://app.securiti.ai/privaci/v1/admin/tenants/configs/setting_export_compressed_csv_format\", \"4-csv_export.json\"),\n",
    "        (\"https://app.securiti.ai/core/v1/admin/tenant/security\", \"5-mfa_password.json\"),\n",
    "        (\"https://app.securiti.ai/privaci/v1/admin/cmp/domain?sort=id&p=1&limit=0\", \"6-cookie_overview.json\"),\n",
    "        (\"https://app.securiti.ai/privaci/v1/admin/dsr/forms/counts\", \"7-dsr_count.json\")\n",
    "    ]\n",
    "    \n",
    "    # Fetch data and save JSON files\n",
    "    for api_url, filename in endpoints:\n",
    "        fetch_and_save_data(api_url, filename, cookies)\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "    # Process JSON files into an Excel file\n",
    "    process_json_to_excel()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch times converted and saved to 'data_with_human_dates.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# Function to convert epoch time (in milliseconds) to human-readable format with timezone awareness\n",
    "def convert_epoch_to_human(epoch_time, timezone='UTC'):\n",
    "    epoch_time_seconds = epoch_time / 1000  # Convert milliseconds to seconds\n",
    "    tz = pytz.timezone(timezone)\n",
    "    dt = datetime.fromtimestamp(epoch_time_seconds, tz=pytz.utc).astimezone(tz)\n",
    "    return dt.strftime('%m-%d-%Y') #%H:%M:%S'\n",
    "\n",
    "# Read the Excel file with all sheets\n",
    "df_sheets = pd.read_excel('merged_data.xlsx', sheet_name=None)  # 'sheet_name=None' reads all sheets into a dictionary\n",
    "\n",
    "# Specify the desired timezone for conversion\n",
    "timezone = 'UTC'  # Modify as needed, e.g., 'America/New_York'\n",
    "\n",
    "# Keywords to look for in column names\n",
    "keywords = ['created_at', 'modified_at', 'timestamp','last_scan_timestamp', 'next_scan_timestamp', 'timestamp', 'published_at']  # Add other keywords as needed\n",
    "\n",
    "# Open an Excel writer to save all processed sheets in one output file\n",
    "with pd.ExcelWriter('data_with_human_dates.xlsx', engine='openpyxl') as writer:\n",
    "    # Loop through each sheet in the Excel file\n",
    "    for sheet_name, sheet_data in df_sheets.items():\n",
    "        # Identify columns that match any keyword in the list\n",
    "        for column in sheet_data.columns:\n",
    "            if any(keyword in column.lower() for keyword in keywords):  # Check if any keyword exists in the column name\n",
    "                # Apply conversion only if the column is likely an epoch timestamp in milliseconds\n",
    "                sheet_data[column] = sheet_data[column].apply(\n",
    "                    lambda x: convert_epoch_to_human(x, timezone) if isinstance(x, (int, float)) and (x > 1000000000000) else x\n",
    "                )\n",
    "        \n",
    "        # Write the processed sheet to the Excel file\n",
    "        sheet_data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(\"Epoch times converted and saved to 'data_with_human_dates.xlsx'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
